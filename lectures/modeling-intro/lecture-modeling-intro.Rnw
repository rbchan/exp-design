\documentclass[color=usenames,dvipsnames]{beamer}
%\documentclass[color=usenames,dvipsnames,handout]{beamer}


\usepackage[sans]{../../lab1}
\usepackage{bm}


\hypersetup{pdftex,pdfstartview=FitV}



<<build-fun, include=FALSE, cache=TRUE, eval=FALSE, purl=FALSE>>=
## A function to compile and open the pdf
source("../rnw2pdf.R")
if(1==2) {
    ## Usage:
    rnw2pdf("lecture-modeling-intro") # Don't include the file extension
    rnw2pdf("lecture-modeling-intro", clean=FALSE) # Don't clean intermediate files
    rnw2pdf("lecture-modeling-intro", tangle=TRUE) # If you want the .R file
}
@


<<knitr-theme, include=FALSE, purl=FALSE>>=
##knit_theme$set("navajo-night")
knit_theme$set("edit-kwrite")
@


%% New command for inline code that isn't to be evaluated
\definecolor{inlinecolor}{rgb}{0.878, 0.918, 0.933}
\newcommand{\inr}[1]{\colorbox{inlinecolor}{\texttt{#1}}}






\begin{document}


%\setlength\fboxsep{0pt}



\begin{frame}[plain]
  \huge
  \centering \par
  \textcolor{NavyBlue}{Introduction to Statistical Modeling} \\
  \vspace{1cm}
  \Large
  November 2, 5, \& 7, 2018 \\
  FANR 6750 \\
  \vfill
  \large
  Richard Chandler and Bob Cooper
\end{frame}


\section{Motivation}



\begin{frame}
  \frametitle{Looking ahead}
  \Large
%  \begin{itemize}
%    \item
  Linear models
%    \item[]
%    \item Linear mixed effects models
%    \item[]
%    \item
  \vfill
  Generalized linear models
%    \item[]
%    \item
  \vfill
  Model selection and multi-model inference
%    \item[]
%    \item Goodness-of-fit
%  \end{itemize}
\end{frame}






\begin{frame}
  \frametitle{Outline}
  \LARGE
   \only<1>{\tableofcontents[hideallsubsections]}
%   \only<2>{\tableofcontents[currentsection,hideallsubsections]}
\end{frame}




\begin{frame}
  \frametitle{Motivation}
  \large
  {\bf Why do we need this part of the course? \par}
  \pause
%\begin{enumerate}[<+- | visible@+->][\bf \color{PineGreen} (1)]
  \begin{itemize}%[<+->]
    \item<2-> We have been modeling all along
    \item[]
    \item<3-> Good experimental design + ANOVA is usually the most direct
      route to causal inference
    \item[]
    \item<4-> Often, however, it isn't possible (or even desirable) to
      control some aspects of the system being investigated
    \item[]
    \item<5-> When manipulative experiments aren't %causal inference isn't
      possible, observational studies
      and predictive models can be the next best option
  \end{itemize}
%\end{enumerate}
% Mention BLOGs
\end{frame}




%% \begin{frame}
%%   \frametitle{Assignment}
%% <<eval=true,echo=false,results=hide>>=
%% set.seed(894)
%% N <- 100
%% a <- 4
%% n <- N/a
%% x <- runif(N, 5, 20)
%% g <- gl(a, n, labels=c("Control", "Low", "Med", "High"))
%% #contrasts(g) <- c("contr.sum", "contr.poly")
%% dat <- data.frame(diet=g, length=x,
%%                   moon=sample(1:4, N, replace=TRUE),
%%                   sun=sample(1:10, N, replace=TRUE))
%% X <- model.matrix(~diet+length, dat)
%% X
%% beta <- c(20, 1, 2, 4, 0.5)
%% mu <- X %*% beta
%% mu
%% sigma <- 2
%% set.seed(52)
%% y <- rnorm(N, mu, sigma)
%% tapply(y, g, mean)
%% dat <- cbind(weight=y, dat)
%% #plot(weight ~ x, dat, col=rep(1:4, each=n))
%% #boxplot(weight ~ diet, dat)
%% write.csv(dat, "dietData.csv", row.names=FALSE)
%% @
%% \end{frame}




%\section{What is a model?}



\begin{frame}
  \frametitle{What is a model?}
%  \begin{block}
%  \large
    {\bf Definition} \\
    A model is an abstraction of reality used to describe the
    relationship between two or more variables \par
%  \end{block}
%    \pause
    \vfill %\vspace{0.5cm}
    \uncover<2->{
    {\bf Types of models}
    \begin{itemize}
      \item Conceptual
      \item Mathematical
      \item Statistical
    \end{itemize}
  }
  \uncover<3->{
  {\bf Important point} \\
  ``All models are wrong but some are useful'' (George Box, 1976) \\
  }
%  \pause
  \vfill
  \begin{columns}%[c]
    \begin{column}{0.65\textwidth}
      %% \uncover<3->{
      %% {\bf Types of models}
      %% \begin{itemize}
      %%   \item Conceptual
      %%   \item Mathematical
      %%   \item Statistical
      %% \end{itemize}
      %% }
    \end{column}
    \begin{column}{0.15\textwidth}
      \uncover<3->{\includegraphics[width=\textwidth]{figs/Box}} \\
    \end{column}
  \end{columns}
\end{frame}




\begin{frame}
  \frametitle{Statistical models}
  \large
  {\bf What are they \alert{useful} for?}
  \begin{itemize}%[<+->]
    \item<2-> Formalizing hypotheses using math and probability
    \item[]
    \item<3-> Evaulating hypotheses by confronting models with data
    \item[]
    \item<4-> Predicting future outcomes
  \end{itemize}
\end{frame}




\begin{frame}
  \frametitle{Statistical models}
  {\bf \large Two important pieces \par}
  \large
%  \begin{enumerate}[<+- | visible@+->][\bf \color{PineGreen} (1)]
  \begin{enumerate}[\bf \color{gb} (1)]
    \large
    \item<1-> Deterministic component%(s)
      \begin{itemize}
        \large
        \item Equation for the expected value of the response
          variable %, denoted $\mathbb{E}(y)$
%        \item Often a linear model (LM), but could be a generalized
%          linear model (GLM), a generalized additive (GAM), or a
%          genearlized linear mixed effects model (GLMM), etc\dots
      \end{itemize}
    \item[]
    \item<2-> Stochastic component %(s)
      \begin{itemize}
        \large
        \item Probability distribution %(s)
          describing the differences
          between the expected values and the observed values
        \item In parametric statistics, we assume we know the
          distribution, but not the parameters of the distribution
      \end{itemize}
  \end{enumerate}
\end{frame}




%% \begin{frame}
%%   \frametitle{Example}
%%   {\bf Motivation \\}
%%   Prey numbers appear to be declining in the core of the Florida panther's range \\
%%   \pause
%%   \vfill
%%   {\bf Questions \\}
%%   How do predation, changing hydrology and hunting regulations
%%   influence white-tailed deer population viability?
%% \end{frame}


%% \begin{frame}
%%   \frametitle{Example -- South Florida Deer Study}
%% %  \begin{center}
%% %  \vspace{-8mm}
%%   \begin{columns}
%%     \begin{column}{0.6\textwidth}
%% %      \large
%%         \normalsize
%%       {\bf Objectives}
%%       \begin{enumerate}
%%         \normalsize
%%         \item[{\bf (1)}] Understand how deer populations are influenced by:
%%         \begin{itemize}
%% %          \large
%%         \normalsize
%%           \item Predation
%%           \item Hydrology
%%           \item Hunting
%%         \end{itemize}
%%         \item[{\bf (2)}] Develop a camera-based monitoring program
%%       \end{enumerate}
%%     \includegraphics[width=0.9\textwidth]{figs/FL-study-area} \\ \vfill
%%     \end{column}
%%     \begin{column}{0.4\textwidth}
%%       \fbox{\includegraphics[width=\textwidth]{figs/puma1}} \\ \vfill
%%       \fbox{\includegraphics[width=\textwidth]{figs/2015-05-12-15-32-13_FP39}}
%%     \end{column}
%%   \end{columns}
%% %  \end{center}
%% \end{frame}









\section{Linear models}



\begin{frame}
  \frametitle{Outline}
  \LARGE
   \tableofcontents[currentsection,hideallsubsections]
\end{frame}



\begin{frame}[fragile]
  \frametitle{Is this a linear model?}
\[
y = 20 + 0.5 x
\]
<<linmod1,include=FALSE,fig.show="hide">>=
par(mai=c(0.8,0.8,0.1,0.1))
plot(function(x) 20 + 0.5*x, 0, 10, ylab="y")
@
\begin{center}
  \includegraphics[width=0.6\textwidth]{figure/linmod1-1}
\end{center}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Is this a linear model?}
\[
y = 20 + 0.5 x - 0.3 x^2
\]
<<linmod2,include=FALSE,fig.show='hide'>>=
par(mai=c(0.8,0.8,0.1,0.1))
plot(function(x) 20 + 0.5*x - 0.3*x^2 , 0, 10, ylab="y")
@
\begin{center}
  \includegraphics[width=0.6\textwidth]{figure/linmod2-1}
\end{center}
\end{frame}





\begin{frame}
  \frametitle{Linear model}
{\bf A linear model is an equation of the form:}

\[
y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \ldots + \beta_p x_{ip} + \varepsilon_i
\]

where the $\beta$'s are coefficients, and the $x$ values are predictor
variables (or dummy variables for categorical predictors).
\pause

\vspace{0.5cm}

{\bf This equation is often expressed in matrix notation as:}

\[
{\bf y} = {\bf X} {\bm{\beta}} + {\bm \varepsilon}
\]

where $\bf X$ is a \alert{design matrix} and $\bm{\beta}$ is a
vector of coefficients. \pause More on matrix notation later\dots
\end{frame}


%\end{document}




\begin{frame}
  \frametitle{Interpretting the $\beta$'s}
You must be able to interpret the $\beta$
coefficients {\it for any model that you fit to your data}.
\pause
\vfill
A linear model might have dozens of continuous and categorical
predictors variables, with dozens of associated $\beta$ coefficients.
\pause
\vfill
%% Key points for interpretting $\beta$'s:
%% \begin{itemize}
%%   \item For continuous explano
%% \end{itemize}
Linear models can also include polynomial terms and interactions
between continuous and categorical predictors
\end{frame}


\begin{frame}
  \frametitle{Interpretting the $\beta$'s}% for continuous explanatory variables}
  The intercept $\beta_0$ is the expected value of $y$, when all $x$'s are 0
  \pause
  \vfill
  If $x$ is a {\bf continuous} explanatory variable: %, $\beta$ is
  \begin{itemize}
    \item $\beta$ can usually be interpretted as a \textit{slope}
      parameter.
    \item In this case, $\beta$ is the
      change in $y$ resulting from a 1 unit change in $x$ (while
      holding the other predictors constant).
  \end{itemize}
%  \pause
%  \vfill
\end{frame}




\begin{frame}[fragile]
  \frametitle{\small Interpretting $\beta$'s for categorical explantory
    variables}
  Things are more complicated for {\bf categorical} explantory
  variables (i.e., factors) because they must be converted to dummy
  variables
  \pause
  \vfill
  There are many ways of creating dummy variables
  \pause
  \vfill
%  For a {\bf categorical} explanatory variable %, $\beta$ is
  In \R, the default method for creating dummy variables from
  unordered factors works like
  this: %unordered factors is called \inr{"contr.treatment"}
  \begin{itemize}
    \item One level of the factor is treated as a \alert{reference level}
    \item The reference level is associated with the intercept
    \item The $\beta$ coefficients for the other levels of the factor
      are differences from the reference level.
  \end{itemize}
  \pause
  \vfill
  The default method corresponds to:
<<contr-trt,size='small'>>=
options(contrasts=c("contr.treatment","contr.poly"))
@
\end{frame}




\begin{frame}[fragile]
  \frametitle{\small Interpretting $\beta$'s for categorical explantory
    variables}
  Another common method for creating dummy variables results in
  $\beta$s that can be interpretted as the $\alpha$'s from the
  additive models that we saw earlier in the class.
  \pause
  \vfill
  With this method:
  \begin{itemize}
    \item The $\beta$ associated with each level of the factor is the
      difference from the intercept
    \item The intercept can be interpetted as the grand mean if the
      continuous variables have been centered
    \item One of the levels of the factor will not be displayed
      because it is redundant when the intercept is estimated
  \end{itemize}
  \pause
  \vfill
  This method corresponds to:
<<contr-sum,size='small',eval=FALSE>>=
options(contrasts=c("contr.sum","contr.poly"))
@
\end{frame}



\section{Example}


\begin{frame}
  \frametitle{Outline}
  \LARGE
   \tableofcontents[currentsection,hideallsubsections]
\end{frame}



\begin{frame}[plain]
  \frametitle{Example}
  \Huge
  \begin{center}
    \includegraphics[width=0.5\textwidth]{figs/issj}
    The Island Scrub-Jay
  \end{center}
\end{frame}



\begin{frame}[plain]
  \frametitle{Example}
  \Huge
%  \begin{center}
  \centering
    Santa Cruz Island \\
  \begin{columns}
    \column{\dimexpr\paperwidth-20pt}
    \includegraphics[width=\textwidth]{figs/Santa-Cruz} \\
  \end{columns}
%  \end{center}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Santa Cruz Data}
  \footnotesize
<<cruz,echo=FALSE,results='hide'>>=
library(unmarked)
head(cruz)
@
<<cruz2,echo=FALSE,results='hide'>>=
cruz2 <- cruz
set.seed(43893)
cruz2$habitat <- factor(sample(c("Pine","Oak","Bare"),
                               size=nrow(cruz2), replace=TRUE,
                               prob=c(0.3, 0.6, 0.1)))
cruz2$seeds <- factor(sample(c("Low","Med","High"),
                               size=nrow(cruz2), replace=TRUE,
                               prob=c(0.3, 0.6, 0.1)))
plots <- sample(1:nrow(cruz2), size=100)
jayData <- cruz2[plots,]
jayX <- model.matrix(~elevation+I(elevation^2)+chaparral+habitat, jayData)
jayBeta <- c(30, 0.01, -0.000001, 1, 2.5, 1.5)
summary(jaymu <- jayX %*% jayBeta)
sigmaSq <- 5
set.seed(4530)
summary(jayData$jays <- round(rnorm(nrow(jayData), jaymu, sqrt(sigmaSq))))
# hist(jayData$jays)
summary(lm(jays ~ elevation + I(elevation^2) + chaparral + habitat + forest + seeds,
           jayData))
@
{\bf Habitat data for all 2787 grid cells covering the island}
<<cruz2-head>>=
head(cruz2)
@
\end{frame}



\begin{frame}[fragile]
  \frametitle{Maps of predictor variables}
%  {\bf Elevation}
  \scriptsize
<<elev,fig.show='hide',fig.width=6,fig.height=4,echo=FALSE>>=
library(lattice)
levelplot(elevation ~ x + y, data=cruz2, aspect="iso",
          scales=list(draw=FALSE),
##          col.regions=rev(topo.colors(101)),
          at=seq(10, 2300, length=100),
          xlab="Easting", ylab="Northing", main="Elevation")
@
\begin{columns}
  \column{\dimexpr\paperwidth-10pt}
  \includegraphics[width=\textwidth]{figure/elev-1}
\end{columns}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Maps of predictor variables}
%  {\bf Forest cover}
  \scriptsize
<<forest,fig.show='hide',fig.width=6,fig.height=4,echo=FALSE>>=
levelplot(forest ~ x + y, data=cruz, aspect="iso",
          xlab="",ylab="",main="Forest Cover",
          col.regions=rev(terrain.colors(100)),
          at=seq(0, 1, length=100),
          scales=list(draw=FALSE))
@
\begin{columns}
  \column{\dimexpr\paperwidth-10pt}
  \includegraphics[width=\textwidth]{figure/forest-1}
\end{columns}
\end{frame}






\begin{frame}
  \frametitle{Questions}
  \large
%  \begin{enumerate}[<+- | visible@+->][\bf \color{PineGreen} (1)]
  \begin{enumerate}[\bf \color{PineGreen} (1)]
    \item How many jays are on the island?
    \item[]
    \item What environmental variables influence abundance?
    \item[]
    \item Can we predict consequences of environmental change?
  \end{enumerate}
\end{frame}



\begin{frame}[fragile]
  \frametitle{Maps of predictor variables}
%  {\bf Chaparral cover}
<<plots,echo=FALSE,fig.show='hide',fig.width=6,fig.height=4>>=
levelplot(chaparral ~ x + y, data=cruz2, aspect="iso",
          xlab="", ylab="", main="Chaparral and survey plots",
          scales=list(draw=FALSE),
          col.regions=heat.colors(100),
          panel = function(...) {
              panel.levelplot(...)
#                  grid.points(jayData$x, jayData$y, pch=0,
#                              size=unit(0.01, "npc"))
              lpoints(jayData$x, jayData$y, pch=0, col=1, cex=0.5)
              }
          )
@
\begin{columns}
  \column{\dimexpr\paperwidth-10pt}
  \includegraphics[width=\textwidth]{figure/plots-1}
\end{columns}
\end{frame}




\begin{frame}[fragile]
  \frametitle{The (fake) jay data}
<<jayData,size='scriptsize'>>=
head(jayData)
@
\end{frame}




\begin{frame}[fragile]
  \frametitle{Simple linear regression}
<<fm1,size='scriptsize'>>=
fm1 <- lm(jays ~ elevation, data=jayData)
summary(fm1)
@
\end{frame}


\begin{frame}[fragile]
  \frametitle{Simple linear regression}
<<pred1,echo=FALSE,fig.width=7,fig.height=5.5>>=
nseq <- 20
elev.seq <- seq(0, 2300, length=nseq)
predData1 <- data.frame(elevation=elev.seq)
pred1 <- predict(fm1, newdata=predData1, interval="confidence", se.fit=TRUE)
plot(jays ~ elevation, jayData, xlab="Elevation (m)", ylab="Jays", cex.lab=1.3)
lines(predData1$elevation, pred1$fit[,1])
lines(predData1$elevation, pred1$fit[,2], lty=3)
lines(predData1$elevation, pred1$fit[,3], lty=3)
@
\end{frame}



\begin{frame}[fragile]
  \frametitle{Multiple linear regression}
<<fm2,size='scriptsize'>>=
fm2 <- lm(jays ~ elevation+forest, data=jayData)
summary(fm2)
@
\end{frame}




\begin{frame}[fragile]
  \frametitle{Multiple linear regression}
<<pred2,echo=FALSE,fig.width=7,fig.height=6>>=
forest.seq <- seq(0,1,length=nseq)
predData2 <- data.frame(elevation=rep(elev.seq, each=nseq),
                        forest=rep(forest.seq, times=nseq))
pred2 <- predict(fm2, newdata=predData2, interval="confidence", se.fit=TRUE)
res <- persp(forest.seq, elev.seq, matrix(pred2$fit[,1],nseq),
             theta=40, phi=20, col=rgb(0,0,1,0.5), zlab="Expected number of jays",
             ylab="Elevation", xlab="Forest cover", zlim=c(30, 55),
             ticktype="detailed")
#points(trans3d(jayData$forest, jayData$elev, jayData$jays, pmat=res),
#       col="red", cex=1.5, pch=16)
@
\end{frame}





\begin{frame}[fragile]
  \frametitle{One-way ANOVA}
<<fm3,size='scriptsize'>>=
fm3 <- lm(jays ~ habitat, data=jayData)
summary(fm3)
@
\end{frame}




\begin{frame}[fragile]
  \frametitle{One-way ANOVA}
<<pred3,echo=FALSE,fig.width=6,fig.height=6,fig.show='hide'>>=
predData3 <- data.frame(habitat=levels(jayData$habitat))
pred3 <- predict(fm3, newdata=predData3, interval="confidence", se.fit=TRUE)
xmid <- barplot(pred3$fit[,1], xlab="Habitat", names=predData3$habitat,
                cex.lab=1.5,
                ylim=c(0, 45), col="darkcyan", ylab="Expected number of jays")
arrows(xmid, pred3$fit[,1], xmid, pred3$fit[,1]+pred3$se, angle=90, length=0.05, code=3)
box()
@
\centering
\includegraphics[width=0.8\textwidth]{figure/pred3-1} \\
\end{frame}





\begin{frame}[fragile]
  \frametitle{ANCOVA}
<<fm4,size='scriptsize'>>=
fm4 <- lm(jays ~ elevation+habitat, data=jayData)
summary(fm4)
@
\end{frame}



\begin{frame}[fragile]
  \frametitle{ANCOVA}
<<pred4,echo=FALSE,fig.width=7,fig.height=5.5>>=
predData4 <- data.frame(elevation=rep(elev.seq, 3),
                        habitat=rep(levels(jayData$habitat), each=nseq))
pred4 <- predict(fm4, newdata=predData4, interval="confidence", se.fit=TRUE)
pred4dat <- data.frame(pred4$fit, predData4)
plot(jays ~ elevation, jayData, xlab="Elevation (m)", ylab="Jays", cex.lab=1.3)
lines(fit~elevation, data=pred4dat, subset=habitat=="Bare", col="tan", lwd=3)
lines(fit~elevation, data=pred4dat, subset=habitat=="Oak", col="brown", lwd=3)
lines(fit~elevation, data=pred4dat, subset=habitat=="Pine", col="darkseagreen", lwd=3)
legend(0, 47, c("Oak", "Pine", "Bare"), col=c("brown","darkseagreen", "tan"), lwd=3)
@
\end{frame}





\begin{frame}[fragile]
  \frametitle{Continuous-categorical interaction}
<<fm5,size='tiny'>>=
fm5 <- lm(jays ~ elevation*habitat, data=jayData)
summary(fm5)
@
\end{frame}




\begin{frame}[fragile]
  \frametitle{Continuous-categorical interaction}
<<pred5,echo=FALSE,fig.width=7,fig.height=5.5>>=
pred5 <- predict(fm5, newdata=predData4, interval="confidence", se.fit=TRUE)
pred5dat <- data.frame(pred5$fit, predData4)
plot(jays ~ elevation, jayData, xlab="Elevation (m)", ylab="Jays", cex.lab=1.3)
lines(fit~elevation, data=pred5dat, subset=habitat=="Bare", col="tan", lwd=3)
lines(fit~elevation, data=pred5dat, subset=habitat=="Oak", col="brown", lwd=3)
lines(fit~elevation, data=pred5dat, subset=habitat=="Pine", col="darkseagreen", lwd=3)
legend(0, 47, c("Oak", "Pine", "Bare"), col=c("brown","darkseagreen", "tan"), lwd=3)
@
\end{frame}






\begin{frame}[fragile]
  \frametitle{Quadratic effect of elevation}
<<fm6,size='scriptsize'>>=
fm6 <- lm(jays ~ elevation+I(elevation^2), data=jayData)
summary(fm6)
@
\end{frame}




\begin{frame}[fragile]
  \frametitle{Quadratic effect of elevation}
<<pred6,echo=FALSE,fig.width=7,fig.height=5.5>>=
nseq <- 20
elev.seq <- seq(0, 2300, length=nseq)
predData6 <- data.frame(elevation=elev.seq)
pred6 <- predict(fm6, newdata=predData6, interval="confidence", se.fit=TRUE)
plot(jays ~ elevation, jayData, xlab="Elevation (m)", ylab="Jays", cex.lab=1.3)
lines(predData6$elevation, pred6$fit[,1])
lines(predData6$elevation, pred6$fit[,2], lty=3)
lines(predData6$elevation, pred6$fit[,3], lty=3)
@
\end{frame}






\begin{frame}[fragile]
  \frametitle{Interaction and quadratic effects}
  \vspace{-2mm}
<<fm7,size='tiny'>>=
fm7 <- lm(jays ~ habitat * forest + elevation +
          I(elevation^2), data=jayData)
summary(fm7)
@
\end{frame}



\begin{frame}[fragile]
  \frametitle{Predict jay abundance at each grid cell}
<<E7>>=
E7 <- predict(fm7, type="response", newdata=cruz2,
              interval="confidence")
@
\pause
<<E72>>=
E7 <- cbind(cruz2[,c("x","y")], E7)
head(E7)
@
\end{frame}


\begin{frame}[fragile]
  \frametitle{Map the predictions}
  \scriptsize
<<Ejay,fig.show='hide',fig.width=6,fig.height=4,echo=FALSE>>=
levelplot(fit ~ x + y, data=E7, aspect="iso",
          xlab="", ylab="", main="Expected number of jays per grid cell",
##          col.regions=heat.colors(101),
          at=22:55, colorkey=list(space="bottom"),
          scales=list(draw=FALSE))
@
\begin{columns}
  \column{\dimexpr\paperwidth-10pt}
  \includegraphics[width=\textwidth]{figure/Ejay-1}
\end{columns}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Map the predictions}
  \scriptsize
<<Ljay,fig.show='hide',fig.width=6,fig.height=4,echo=FALSE>>=
levelplot(lwr ~ x + y, data=E7, aspect="iso",
          xlab="", ylab="", main="Lower CI",
          at=25:55, colorkey=list(space="bottom"),
          scales=list(draw=FALSE))
@
\begin{columns}
  \column{\dimexpr\paperwidth-10pt}
  \includegraphics[width=\textwidth]{figure/Ljay-1}
\end{columns}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Map the predictions}
  \scriptsize
<<Ujay,fig.show='hide',fig.width=6,fig.height=4,echo=FALSE>>=
levelplot(upr ~ x + y, data=E7, aspect="iso",
          xlab="", ylab="", main="Upper CI",
          at=25:55, colorkey=list(space="bottom"),
          scales=list(draw=FALSE))
@
\begin{columns}
  \column{\dimexpr\paperwidth-10pt}
  \includegraphics[width=\textwidth]{figure/Ujay-1}
\end{columns}
\end{frame}




%% \begin{frame}[fragile]
%%   \frametitle{Future scenarios}
%%   {\bf What if the pine and oak disappear? \par}
%%   \pause
%%   \vspace{0.3cm}
%%   {\bf \dots assuming {\tt fm5} is the {\it correct} model}
%%   \pause
%%   \vspace{0.3cm}
%%   \footnotesize
%% <<>>=
%% future1 <- cruz2
%% future1$habitat[] <- "Bare"
%% future.pred1 <- predict(fm5, type="response", newdata=future1,
%%                         interval="confidence")
%% future.pred1 <- cbind(cruz2[,c("x","y")], future.pred1)
%% @
%% \end{frame}



\begin{frame}[fragile]
  \frametitle{Future scenarios}
  {\bf What if pine and oak disapper? \par}
  \scriptsize
<<future1,echo=FALSE>>=
future1 <- cruz2
future1$habitat[] <- "Bare"
future.pred1 <- predict(fm6, type="response", newdata=future1,
                        interval="confidence")
future.pred1 <- cbind(cruz2[,c("x","y")], future.pred1)
@
<<future1fig,fig.show='hide',fig.width=6,fig.height=4,echo=FALSE>>=
levelplot(fit ~ x + y, data=future.pred1, aspect="iso",
          xlab="", ylab="", main="Expected values",
          at=25:55, colorkey=list(space="bottom"),
          scales=list(draw=FALSE))
@
\begin{columns}
  \column{\dimexpr\paperwidth-10pt}
  \only<1>{\includegraphics[width=\textwidth]{figure/Ejay-1} \\}
  \only<2>{\includegraphics[width=\textwidth]{figure/future1fig-1} \\}
\end{columns}
\end{frame}





%% \begin{frame}[fragile]
%%   \frametitle{Future scenarios}
%%   {\bf What if the island sinks 1000 m? \par}
%%   \vspace{0.3cm}
%% %  \pause
%% %  {\bf \dots assuming {\tt fm5} is the {\it correct} model}
%%   \pause
%%   \footnotesize
%% <<>>=
%% future2 <- cruz2
%% future2$elevation <- future2$elevation - 1000
%% future2$elevation[future2$elevation < 0] <- NA
%% future.pred2 <- predict(fm5, type="response", newdata=future2,
%%                         interval="confidence")
%% future.pred2 <- cbind(cruz2[,c("x","y")], future.pred2)
%% @
%% \end{frame}




\begin{frame}[fragile]
  \frametitle{Future scenarios}
  {\bf What if sea level rises? \par}
  \scriptsize
  \pause
<<future2,echo=FALSE>>=
future2 <- cruz2
future2$elevation <- future2$elevation - 1000
future2$elevation[future2$elevation < 0] <- NA
future.pred2 <- predict(fm6, type="response", newdata=future2,
                        interval="confidence")
future.pred2 <- cbind(cruz2[,c("x","y")], future.pred2)
@
<<future2fig,echo=FALSE,fig.show='hide',fig.width=6,fig.height=4>>=
levelplot(fit ~ x + y, data=future.pred2, aspect="iso",
          panel = function(...) {
              panel.fill(col="skyblue1")
              panel.levelplot(...)
          },
          xlab="", ylab="", main="Expected values",
          at=25:55, colorkey=list(space="bottom"),
          scales=list(draw=FALSE))
@
\begin{columns}
  \column{\dimexpr\paperwidth-10pt}
  \includegraphics[width=\textwidth]{figure/future2fig-1}
\end{columns}
\end{frame}



%% \begin{frame}
%%   \frametitle{Worse yet \dots}
%%   \pause
%%   \huge
%%   What if our model is wrong?
%% \end{frame}












\section{Matrix notation}


\begin{frame}
  \frametitle{Outline}
  \LARGE
   \tableofcontents[currentsection,hideallsubsections]
\end{frame}



\begin{frame}
  \frametitle{Matrix notation}
  Linear models are often expressed in matrix notation \\
  \vfill
  There are two reasons for this: \\
  \begin{itemize}%[(1)]
    \item It is more compact and therefore easier to write
    \item Matrix multiplication is fast on a computer
  \end{itemize}
\end{frame}



\begin{frame}
  \frametitle{Linear model}
  {\bf All of the fixed effects models that we have covered can be
    expressed this way:}
  \[
  {\bf y} = {\bf X}{\bm \beta} + {\bm \varepsilon}
  \]
  {\bf where}
  \[
  {\bm \varepsilon} \sim \mbox{Normal}(0, \sigma^2)
  \]
  \pause
  \vfill
  {\bf Examples include} \\
  \begin{itemize}
    \item Completely randomized ANOVA
    \item Randomized complete block designs with fixed block effects
    \item Factorial designs
    \item ANCOVA
  \end{itemize}
\end{frame}






\begin{frame}
  \frametitle{Then how do they differ?}
%  \pause
  \begin{itemize}%[<+->]
  \large
    \item The design matrices are different
    \item[]
    \item And so are the number of parameters (coefficients) to be
      estimated
    \item[]
    \item Important to understand how to construct design matrix that
      includes categorical variables
  \end{itemize}
\end{frame}




\begin{frame}%[fragile]
  \frametitle{Design matrix}
%  \large
%  \begin{itemize}[<+->]
%    \item
  A design matrix has $N$ rows and $K$ columns, where $N$ is
      the total sample size and $K$ is the number of coefficients (parameters)
      to be estimated. \\
 \pause
 \vfill
%    \item
      The first column contains just 1's. This column corresponds
      to the intercept ($\beta_0$) \\
 \pause
 \vfill
%    \item
      Continuous predictor variables appear unchanged in the design
      matrix \\
 \pause
 \vfill
%    \item
      Categorical predictor variables appear as dummy variables \\
 \pause
 \vfill
%    \item
      In {\bf R}, the design matrix is created internally based on
      the formula that you provide \\
 \pause
 \vfill
%    \item
      The design matrix can be viewed using the \inr{model.matrix} function
%  \end{itemize}
\end{frame}





%% \begin{frame}[fragile]
%%   \frametitle{Design matrix for linear regression}
%%   \begin{columns}
%%     \begin{column}{0.5\textwidth}
%%     {\bf Data}
%%       \scriptsize %\tiny
%% %<<>>=
%% %options(digits=2)
%% %@
%% <<dietData,size='scriptsize'>>=
%% dietData <- read.csv("dietData.csv")
%% head(dietData, n=10)
%% @
%%     \end{column}
%%     \pause
%%     \begin{column}{0.5\textwidth}
%%       {\bf Design matrix}
%%       \scriptsize %\tiny
%% <<X1,size='scriptsize'>>=
%% X1 <- model.matrix(~age,
%%                    data=dietData)
%% head(X1, n=10)
%% @
%%     \end{column}
%%   \end{columns}
%%   \pause
%%   \vfill
%%   {\centering \bf How do we multiply this design matrix ($\bf X$) by
%%     the vector of regression coefficients ($\bm \beta$)? \par}
%% \end{frame}








\begin{frame}[fragile]
  \frametitle{Design matrix for linear regression}
%  \begin{columns}
%    \begin{column}{0.5\textwidth}
  \scriptsize %\tiny
    {Model}
<<fm1-2,size='scriptsize',eval=FALSE>>=
fm1 <- lm(jays ~ elevation, data=jayData)
@
%    \end{column}
    \pause
    \vfill
%    \begin{column}{0.5\textwidth}
      {Design matrix}
      \scriptsize %\tiny
<<X1,size='scriptsize'>>=
X1 <- model.matrix(fm1)
head(X1, n=5) # First 5 rows of design matrix
@
%    \end{column}
%  \end{columns}
      {Estimated $\beta$ coefficients}
      \scriptsize %\tiny
<<beta-hat,size='scriptsize'>>=
beta.hat <- coef(fm1) # Estimates of beta0 and beta1
beta.hat
@
  \pause
  \vfill
  {\centering How do we multiply the design matrix ($\bf X$) by
    the vector of regression coefficients ($\bm \beta$)? \\}
\end{frame}








\begin{frame}
  \frametitle{Matrix multiplication}
  \Large
  \begin{center}
    \[
      \mathbb{E}({\bf y}) = {\bf X}{\bm \beta}
    \]
    \[
    \uncover<3->{
    \begin{bmatrix}
      aw + bx + cy + dz \\
      ew + fx + gy + hz \\
      iw + jx + ky + lz %\\
%      mw + nx + oy + pz
    \end{bmatrix}
    }
    \uncover<2->{=}
    \uncover<2->{
    \begin{bmatrix}
      a & b & c & d \\
      e & f & g & h \\
      i & j & k & l %\\
%      m & n & o & p
    \end{bmatrix}
    }
    \uncover<2->{
    \times
    \begin{bmatrix}
      w \\
      x \\
      y \\
      z
    \end{bmatrix}
    }
    \]
  \end{center}
  \normalsize
  \uncover<4->{
    {\bf In this example}}
    \begin{itemize}
      \item<4-> The first matrix corresponds to the expected values of $\bm y$
      \item<4-> The second matrix corresponds to the design matrix {$\bf X$}
      \item<4-> The third matrix corresponds to {$\bm \beta$}
    \end{itemize}
\end{frame}






\begin{frame}[fragile]
  \frametitle{Matrix multiplication}
%% {\bf \centering The vector of coefficients \\}
%% %\small
%% <<beta,size='small'>>=
%% beta <- coef(fm1)
%% beta
%% @
%% \pause
%\large
\begin{center}
  {$\mathbb{E}({\bf y}) = {\bf X}{\bm \beta}$ or $\mathbb{E}(y_i) = \beta_0 + \beta_1 \mathrm{ELEV}_i$}
\end{center}
\pause
\small
<<Ey1,size='footnotesize'>>=
Ey1 <- X1 %*% beta.hat # Expected number of jays at each site
head(Ey1, 5)
@
\end{frame}









\begin{frame}[fragile]
  \frametitle{Design matrix for ANCOVA}
  \scriptsize %\tiny
    {Model}
<<fm4-2,size='scriptsize',eval=FALSE>>=
fm4 <- lm(jays ~ elevation + habitat, data=jayData)
@
\pause
\vfill
{Design matrix}

<<X4,size='scriptsize'>>=
X4 <- model.matrix(fm4)
head(X4, n=5) # First 5 rows of design matrix
@

{Estimated $\beta$ coefficients}
<<beta-hat4,size='scriptsize'>>=
beta.hat4 <- coef(fm4) # Estimates of beta0 and beta1
beta.hat4
@
\pause
\vfill
{\centering How do we multiply the design matrix ($\bf X$) by
 the vector of regression coefficients ($\bm \beta$)? \\}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Matrix multiplication}
\begin{center}
  \small
  {$\mathbb{E}({\bf y}) = {\bf X}{\bm \beta}$ or $\mathbb{E}(y_i) = \beta_0 +
    \beta_1 \mathrm{ELEV}_i + \beta_2 \mathrm{OAK}_i + \beta_3 \mathrm{PINE}_i$}
\end{center}
\pause
\small
<<Ey4,size='footnotesize'>>=
Ey4 <- X4 %*% beta.hat4 # Expected number of jays at each site
head(Ey4, 5)
@
\end{frame}










\begin{frame}
  \frametitle{Summary}
  Linear models are the foundation of modern statistical modeling
  techniques \\
  \pause
  \vfill
  They can be used to model a wide array of biological processes, and
  they can be easily extended when their assumptions do not hold \\
  \pause
  \vfill
  One of the most important extensions is to cases where the residuals
  are not normally distributed. Generalized linear models address this
  issue.
\end{frame}





%\subsection{Distributions}




%\subsection{Fixed effects models}



%% \begin{frame}
%%   \frametitle{Linear regression}
%% {\bf Deterministic part:}
%% %\[
%% %\mu_i = \mathbb{E}(\bf y) = \beta_0 + \beta_1x_i
%% %\]
%% %\pause
%% %{\bf The same thing, using matrix notation:}
%% \[
%% {\bm \mu} = \mathbb{E}(\bf y) = {\bf X}{\bm \beta}
%% \]
%% \pause
%% {\bf Stochastic part:}
%% %\[
%% %y_i \sim \mbox{Normal}(\mu_i, \sigma^2)
%% %\]
%% %\pause
%% %\centering or \par
%% \[
%% \varepsilon_i \sim \mbox{Normal}(0, \sigma^2)
%% \]
%% \end{frame}




%% \begin{frame}
%%   \frametitle{One-way ANOVA}
%% {\bf Deterministic part:}
%% \[
%% {\bm \mu} = \mathbb{E}(\bf y) = {\bf X}{\bm \beta}
%% \]
%% {\bf Stochastic part:}
%% %\[
%% %y_i \sim \mbox{Normal}(\mu_i, \sigma^2)
%% %\]
%% \[
%% \varepsilon_i \sim \mbox{Normal}(0, \sigma^2)
%% \]
%% \end{frame}




%% \begin{frame}
%%   \frametitle{A$\times$B Factorial ANOVA}
%% {\bf Deterministic part:}
%% \[
%% {\bm \mu} = \mathbb{E}(\bf y) = {\bf X}{\bm \beta}
%% \]
%% {\bf Stochastic part:}
%% %\[
%% %y_i \sim \mbox{Normal}(\mu_i, \sigma^2)
%% %\]
%% \[
%% \varepsilon_i \sim \mbox{Normal}(0, \sigma^2)
%% \]
%% \end{frame}



%% \begin{frame}
%%   \frametitle{A$\times$B$\times$C Factorial ANOVA}
%% {\bf Deterministic part:}
%% \[
%% {\bm \mu} = \mathbb{E}(\bf y) = {\bf X}{\bm \beta}
%% \]
%% {\bf Stochastic part:}
%% %\[
%% %y_i \sim \mbox{Normal}(\mu_i, \sigma^2)
%% %\]
%% \[
%% \varepsilon_i \sim \mbox{Normal}(0, \sigma^2)
%% \]
%% \end{frame}



%% \begin{frame}
%%   \frametitle{ANCOVA}
%% {\bf Deterministic part:}
%% \[
%% {\bm \mu} = \mathbb{E}(\bf y) = {\bf X}{\bm \beta}
%% \]
%% {\bf Stochastic part:}
%% %\[
%% %y_i \sim \mbox{Normal}(\mu_i, \sigma^2)
%% %\]
%% \[
%% \varepsilon_i \sim \mbox{Normal}(0, \sigma^2)
%% \]
%% \end{frame}



%% \begin{frame}
%%   \frametitle{Another equivalent expression}
%%   {\bf General linear model}
%%   \[
%%   {\bf y} = {\bf X}{\bm \beta} + {\bm \epsilon}
%%   \]
%%   {\bf where}
%%   \[
%%   {\bm \epsilon} \sim \mbox{Normal}(0, {\bf I}\sigma^2)
%%   \]
%% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{One-way ANOVA}
%   \scriptsize %\tiny
% <<lm2,size='scriptsize'>>=
% lm2 <- lm(weight ~ diet, data=dietData)
% summary(lm2)
% @
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{One-way ANOVA: Design matrix}
% <<X2>>=
% X2 <- model.matrix(~diet, data=dietData)
% X2[20:30,]
% @
% \end{frame}


% \begin{frame}[fragile]
%   \frametitle{One-way ANOVA: Expected values of $y$}
%   \footnotesize %\scriptsize
% <<betas2,size='footnotesize'>>=
% betas2 <- coef(lm2)
% betas2
% @
% \pause
% <<Ey2,size='footnotesize'>>=
% Ey2 <- X2 %*% betas2
% head(Ey2)
% @
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{ANCOVA}
%   \vspace{-2mm}
%   \scriptsize %\tiny
% <<lm3,size='scriptsize'>>=
% lm3 <- lm(weight ~ age + diet, data=dietData)
% summary(lm3)
% @
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{ANCOVA: Design matrix}
% <<X3>>=
% X3 <- model.matrix(~age+diet, data=dietData)
% X3[20:30,]
% @
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{ANCOVA: Expected values of $y$}
%   \footnotesize
% <<betas3,size='footnotesize'>>=
% betas3 <- coef(lm3)
% betas3
% @
% <<Ey3,size='footnotesize'>>=
% Ey3 <- X3 %*% betas3
% head(Ey3)
% @
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Beyond ANCOVA}
%   {\bf Now the slopes differ for each treatment}
%   \tiny
% <<lm4,size='tiny'>>=
% lm4 <- lm(weight ~ diet * age, data=dietData)
% summary(lm4)
% @
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{The associated design matrix}
%   \tiny
% <<X4,size='tiny'>>=
% X4 <- model.matrix(~ diet * age, data=dietData)
% X4[20:30,]
% @
% \pause
% <<betas4>>=
% betas4 <- coef(lm4)
% Ey4 <- X4 %*% betas4
% @
% \end{frame}





%% \begin{frame}[fragile]
%%   \frametitle{Beyond ANCOVA}
%%   {\bf ... and we test for a moon effect}
%%   \tiny
%% <<>>=
%% lm3 <- lm(weight ~ diet * age + moon, data=dietData)
%% summary(lm3)
%% @
%% \end{frame}


%% \begin{frame}
%%   \frametitle{Mixed effects models}
%% {\bf The notation is only slightly more complex}
%% \end{frame}



%\subsection{Mixed effects models}









\end{document}

