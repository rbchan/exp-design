\documentclass[color=usenames,dvipsnames]{beamer}\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0, 0, 0}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.69,0.494,0}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.749,0.012,0.012}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.514,0.506,0.514}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0,0.341,0.682}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.004,0.004,0.506}{#1}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
%\documentclass[color=usenames,dvipsnames,handout]{beamer}




\usepackage[sans]{../../lab1}
\usepackage{bm}


\hypersetup{pdftex,pdfstartview=FitV}









%% New command for inline code that isn't to be evaluated
\definecolor{inlinecolor}{rgb}{0.878, 0.918, 0.933}
\newcommand{\inr}[1]{\colorbox{inlinecolor}{\texttt{#1}}}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}


%\setlength\fboxsep{0pt}



\begin{frame}[plain]
%  \maketitle
%  \huge
  \LARGE
  \centering \par
  {\color{NavyBlue}{ Model Selection and %\\
  Multimodel Inference \\}}
  \vspace{1cm}
%  \LARGE
  \large
  FANR 6750 \\
%  November 14 \& 26, 2018
\end{frame}


\section{Introduction}



%% \begin{frame}
%%   \frametitle{References}
%%   {\bf Well known book:} \\
%%   Burnham, K.P. and D.R. Anderson. 2002. Model Selection and
%%   Multimodel Inference. Springer.\\
%%   \vspace{0.5cm}
%%   {\bf Great overview:} \\
%%   \url{http://www.stats.ox.ac.uk/~ripley/ModelChoice.pdf} \\
%% \end{frame}



\begin{frame}
  \frametitle{Overview}
  As scientists, we usually have more than one hypothesis \\
  \pause
  \vfill
  Consequently, we usually want to evaluate more than one model \\
  \pause
  \vfill
  {\bf Model selection} is the process of choosing which model is most
  supported by our data \\
  \pause
  \vfill
  In cases where more than one model is highly supported, we can make
  inferences from multiple models using {\bf model averaging} \\
\end{frame}



\begin{frame}
  \frametitle{Questions}
  \large
  {How do we know which model is best? \par}
  \pause
  \vspace{0.9cm}
  { Are any of them any good? \par}
  \pause
  \vspace{0.9cm}
  {What is a good model? \par}
\end{frame}


\begin{frame}
  \frametitle{What is a good model?}
%  \large
  {\bf Explanation \par}
  A good model should be a good approximation of reality. It should
  describe how things actually work. \\
  \pause
  \vspace{0.25cm}
  In other words, a good model should describe the processes that give
  rise to the patterns we observe. \\   
  \pause
  \vspace{0.5cm}
  {\bf Prediction \par}
  A good model should have good predictive abilities. 
\end{frame}



\begin{frame}
  \frametitle{Explanation}
  \large
As scientists, we want
\begin{quote}
  ``an explanation that is as simple as possible, but no simpler''
\end{quote}
{\small \flushright Einstein (paraphrased by Reader's Digest!) \par}
\pause
\vspace{1cm}
Why do we want simplicity? %\\
%\pause
%\begin{quote}
%  ``All models are wrong but some are useful''
%\end{quote}
%{\small \flushright G.E.P. Box, 1976 \par}
\end{frame}




\begin{frame}
  \frametitle{Fit and over-fit}
  \large
%  {\bf $r^2$ is a measure of model fit \par}
  {$r^2$ is a measure of model fit \par}
  \vspace{1cm}
  \pause
%  {\bf Questions}
  {Questions}
  \begin{itemize}%[<+->]
    \item<2-> Does the addition of a new predictor variable always
      increase $r^2$?
    \item<3-> Do we want the model with the highest $r^2$?
    \item<4-> What is the harm in adding ``extra'' predictor variables?
  \end{itemize}
  \vfill
  \uncover<5->{Overly-complicated models don't predict well. They are
    too specific to a particular dataset.}
\end{frame}



\begin{frame}
  \frametitle{Fit and overfit}
  \centering
  \includegraphics[width=0.8\textwidth]{Overfitted_data}   \\
  \pause
  \vfill
  Much more info here: \url{https://speakerdeck.com/rmcelreath/l08-statistical-rethinking-winter-2019?slide=28}  
\end{frame}



\begin{frame}
  \frametitle{Prediction}
  \large
  Predictive ability is assessed by comparing observed and expected
  values. \\ 
  \pause
  \vfill
  In non-scientific fields, we might not care about describing how
  things actually work. We might only care about prediction. \par
  \pause
  \vfill
  However, in scientific contexts we want models that are good at
  description and prediction.
  \pause
  \vfill
  Excellent paper: \\
  \normalsize
  Breiman, L. (2001). Statistical modeling: The two cultures (with
  comments and a rejoinder by the author). Statistical Science, 16(3),
  199-231. \\
\end{frame}




\begin{frame}
  \frametitle{Model Selection Approaches}
  Comparison of 2 models
  \begin{itemize}
    \item $F$-test
    \item Likelihood-ratio ($\chi^2$) test
  \end{itemize}
  \pause
  Stepwise procedures
  \begin{itemize}
    \item Forward-selection
    \item Backward selection
    \item Stepwise selection
  \end{itemize}
  \pause
  Information-theortic approaches
  \begin{itemize}
    \item Akaike's Information Criterion (AIC)
    \item Bayesian Information Criterio (BIC)
  \end{itemize}
  \pause
  Cross-validation
  \begin{itemize}
    \item Leave-one-out
    \item $K$-fold %cross-validation
  \end{itemize}
  \pause
  Out-of-sample validation
  \begin{itemize}
    \item Compare predictions to new data
  \end{itemize}
\end{frame}




\section{AIC}





\begin{frame}[fragile]
  \frametitle{AIC}
  \large
  Minus twice the (maximized) log-likelihood plus two times the number of
  parameters
\[
 \mathrm{AIC} = -2\mathcal{L}(\hat{\theta} ; {\bf y}) + 2K
\]
  \pause
  Or, when ordinary least squares (OLS) is used for estimation, AIC is
  based on the residual sums-of-squares (RSS):
\[
 \mathrm{AIC} = n\log(\mathrm{RSS}/n) + 2K
\]
 \pause
 The key is to recognize that
\[
 \mathrm{AIC} = \text{measure of fit} + \text{complexity penalty}
\]
%  \begin{align*}
%  \mathrm{AIC} &=& -2\mathcal{L}(\theta|{\bf y}) &+ 2K \\
%               &=& \text{measure of fit} &+ \text{complexity penalty}
                                            %    \end{align*}
  \pause
  AIC is asymtotically equivalent to leave-one-out cross-validation \\
\end{frame}




\begin{frame}
  \frametitle{AIC in practice}
  \large
%  {\bf The process}
\begin{enumerate}[<+- | visible@+->][\bf \color{PineGreen} (1)]
  \item Select a set of candidate models
  \item Fit the models to the data (maximize the likelihood or
    minimize the RSS)
  \item Compute the AIC of each model
  \item Rank the models by AIC (lower AIC is better)
  \item Compute the difference in AIC scores between the
    best model, and every other model.
    \[
    \Delta_i = \text{AIC}_i - \text{AIC}_{min}
    \]
  \item Compute the so-called Akaike weight of each model:
    \[
    w_i = \frac{\exp(-1/2\Delta_i)}{\sum_i \exp(-1/2\Delta_i)}
    \]
  \item A model with $w=0.6$ is twice as likely to be the best model
    in the set as a model with $w=0.3$
\end{enumerate}
\end{frame}



\begin{frame}
  \frametitle{Presentation of results}
  \begin{center}
    \begin{tabular}{lrrrrr}
      \hline
      Model  & RSS$^1$ & K$^2$ & AIC & $\Delta$AIC & weight \\
      \hline
      1 & 300 & 2 & 113.8 & 0.0    & 0.98 \\
      2 & 320 & 3 & 122.3 & 8.4    & 0.02 \\
      3 & 330 & 3 & 125.4 & 11.5   & 0.00 \\
      4 & 330 & 5 & 129.4 & 15.5   & 0.00 \\
      \hline
    \end{tabular} \par
    \scriptsize
    $^1$Residual sum-of-squares (replace with log-likelihood if using
    maximum likelihood) \\
    $^2$Number of parameters in model (including $\sigma^2$) \par
  \end{center}
\end{frame}



\begin{frame}
  \frametitle{Small sample size adjustment}
  The last term is the ``bias adjustment term''
  \[
  \mathrm{AIC}_c = n\log(\mathrm{RSS}/n) + 2K + \frac{2K(K+1)}{n-K-1}
  \]
\end{frame}



%% \begin{frame}
%%   \frametitle{Dealing with overdispersion}
%%   \large
%%   {\centering \bf \Large \color{PineGreen} If data are more variable than
%%     allowed by the model, the data are said to be overdispersed \par}
%%   \vspace{0.2cm}
%%   \pause
%%   {\bf One way to deal with this problem is to modify AIC and the SEs}
%%   \pause
%%   \Large
%%   \[
%%      \mathrm{QAIC} = -2\mathcal{L}(\hat{\theta} | {\bf y})/\alert{\hat{c}} + 2K
%%   \]
%%   \pause
%%   \vspace{0.5cm}
%%   where
%%   \vspace{0.5cm}
%%   \[
%%     \alert{\hat{c}} = \chi^2/df
%%   \]
%% \end{frame}



%% \begin{frame}[fragile]
%%   \frametitle{Dealing with overdispersion in \R}
%%   {\bf Overdispersed data}
%% <<>>=
%% y <- rnbinom(100, mu=3, size=0.5)
%% fm <- glm(y ~ 1, poisson)
%% @
%% \pause
%%   {\bf Calculating $\hat{c}$}
%% <<>>=
%% chiSq <- sum((y - fitted(fm))^2 / fitted(fm))
%% df <- anova(fm)$"Resid. Df"
%% c.hat <- chiSq / df
%% c.hat
%% @
%% \pause
%%   {\bf Calculating QAIC}
%% <<>>=
%% K <- length(coef(fm)) + 1 # Must add 1 for c.hat
%% QAIC <- as.numeric(-2*logLik(fm)/c.hat + 2*K)
%% QAIC
%% @
%% \end{frame}




%% \begin{frame}[fragile]
%%   \frametitle{Dealing with overdispersion in \R}
%%   {\bf \R~will adjust SEs and report c.hat, but not QAIC}
%%   \footnotesize
%% <<>>=
%% summary(glm(y ~ 1, quasipoisson))
%% @
%% \end{frame}


%% \begin{frame}
%%   \frametitle{Dealing with overdispersion}
%%   {\bf This approach simply adjusts the SEs and AIC: \par}
%%   \pause
%%   \vspace{0.5cm}
%%   {\bf A better approach would be to fit a different model:}
%%   \begin{itemize}
%%     \item Negative binomial
%%     \item Zero-inflated Poisson
%%     \item Random effects model
%%   \end{itemize}
%%   \pause
%%   \vspace{0.5cm}
%%   {\bf Or use the non-parametric bootstrap}
%% \end{frame}





\begin{frame}
  \frametitle{Notes about AIC}
%  \Large
%  \begin{itemize}[<+->]
%    \item AIC is not a test
    AIC is not a test
    \pause
    \vfill
%    \item AIC is a relative measure. You can't compare the AICs of
%      models fit to different datasets.
    AIC is a relative measure. You can't compare the AICs of
      models fit to different datasets.
%    \item In other words, all models must be fit to the {\it
%        exact} same data
    \pause
    \vfill
    In other words, all models must be fit to the {\it
        exact} same data
%    \item There will always be a model with the lowest AIC. But all of
%      the models in the set could be terrible.
    \pause
    \vfill
    There will always be a model with the lowest AIC. But all of
      the models in the set could be terrible.
    \pause
    \vfill
    Always assess the fit of your best model.
%  \end{itemize}
\end{frame}





\begin{frame}
  \frametitle{\normalsize AIC as an alternative to null hypothesis testing} %Limitations of $p$-values}
%  \large
  The use of AIC avoids some of the limitations of null hypothesis
  testing, such as: \\
%  \pause
%  \vfill
  \begin{itemize}
    \item Null hypotheses are rarely true %\pause \vfill 
    \item A $p$-value tells us nothing about the alternative hypothesis %\pause \vfill
    \item Specification of $\alpha$ is arbitrary %\pause \vfill 
    \item Statistical significance is a function of sample size %\pause \vfill 
    \item Statistical significance does not equal biological significance
  \end{itemize}
%  \pause
%  \vfill
%  \centering \bf
\end{frame}







%% \section{Model Selection in {\bf R}}




%% \begin{frame}[plain]
%%   \frametitle{Today's Topics}
%%   \LARGE
%%   \only<1>{\tableofcontents}%[hideallsubsections]}
%%   \only<2 | handout:0>{\tableofcontents[currentsection]}%,hideallsubsections]}
%% \end{frame}




%% \begin{frame}[fragile]
%%   \frametitle{Swiss Data}
%%   \small
%% <<>>=
%% swissData <- read.csv("swissData.csv")
%% head(swissData, n=11)
%% @
%% \end{frame}


%% \begin{frame}[fragile]
%%   \frametitle{Four linear models}
%% <<>>=
%% fm1 <- lm(sppRichness ~ forest, data=swissData)
%% fm2 <- lm(sppRichness ~ elevation, data=swissData)
%% fm3 <- lm(sppRichness ~ forest + elevation +
%%           water, data=swissData)
%% fm4 <- lm(sppRichness ~ forest + I(forest^2) +
%%           elevation * water, data=swissData)
%% @
%% \end{frame}



%% \begin{frame}[fragile]
%%   \frametitle{Model 4}
%%   \scriptsize
%% <<>>=
%% summary(fm4)
%% @
%% \end{frame}









%% \begin{frame}[fragile]
%%   \frametitle{Compute AIC for each model}
%%   {\bf Sample size}
%% <<>>=
%% n <- nrow(swissData)
%% @
%% \pause
%% \vfill
%% {\bf Residual sums-of-squares (from ANOVA table)}
%% <<>>=
%% RSS <- c(17735, 17089, 30910, 6129)
%% @
%% \pause
%% \vfill
%% {\bf Number of parameters}
%% <<>>=
%% K <- c(3, 3, 3, 7)
%% @
%% \pause
%% \vfill
%% {\bf AIC}
%% <<>>=
%% AIC <- n*log(RSS/n) + 2*K
%% @
%% \pause
%% \vfill
%%   {\bf $\Delta$AIC}
%% <<>>=
%% delta <- AIC - min(AIC)
%% @
%% \pause
%% \vfill
%%   {\bf AIC Weights}
%% <<>>=
%% w <- exp(-0.5*delta)/sum(exp(-0.5*delta))
%% @
%% \end{frame}




%% \begin{frame}[fragile]
%%   \frametitle{AIC table}
%%   \small
%%   {\bf Put vectors in data.frame}
%% <<>>=
%% ms <- data.frame(RSS, K, AIC, delta, w)
%% rownames(ms) <- c("fm1", "fm2", "fm3", "fm4")
%% round(ms)
%% @
%% \pause
%%   {\bf Sort data.frame based on AIC values}
%% <<>>=
%% ms <- ms[order(ms$AIC),]
%% round(ms)
%% @

%% \end{frame}





%% \begin{frame}[fragile]
%%   \frametitle{Similar process using R's {\tt AIC} function}
%% <<>>=
%% AIC(fm1, fm2, fm3, fm4)
%% @
%% \pause
%% \vfill
%% {\bf Notes}
%% \begin{itemize}[<+->]
%%   \item {\bf R} uses {\tt logLik(fm)} instead of {\tt n*log(RSS/n)}
%%   \item AIC values are different but $\Delta$AIC values are the same
%%   \item Either approach is fine with linear models, but log-likelihood
%%     must be used with GLMs, and other models fit using maximum likelihood
%% \end{itemize}
%% \end{frame}







\section{Multi-model Inference}


\begin{frame}
  \frametitle{Multi-model Inference}
  \large
%  {\bf What if several models have similar weights? \par}
  What if several models have similar weights? \par
%  \begin{itemize}
%    \item Reliance on a single model ignores model selection uncertainty
%    \item It also ignore the fact that your alternative hypotheses
%      have support
%  \end{itemize}
  \pause
  \vspace{1cm}
%  {\bf Multi-model inference involves using {\it all} of the models in
%    the set of models}
  Multi-model inference involves using {\it all} of the models in
    the set of models
%  \begin{itemize}
%    \item Parameters (or predictions) are weighted by $w$
%  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Multi-model Inference}
  \large
%  {\bf The key is to do a \alert{weighted average} of parameters or
%    predictions \par}
  The key is to do a \alert{weighted average} of parameters or
    predictions \par
  \pause
%  {\bf Weighted average:}
  \[
    \bar{\hat{\theta}} = \sum_{i=1}^R \hat{\theta_i}w_i
  \]
  \pause
%  {\bf where $\theta_i$ is a parameter or a predicted value from model $i$
%    in the set of $R$ models.}
  where $\theta_i$ is a parameter or a predicted value from model $i$
    in the set of $R$ models.
\end{frame}



\begin{frame}
  \frametitle{Averaging parameters}
  \large
%  {\bf In the case of linear models, we might want to average the
%    $\beta$ parameters \par}
  {In the case of linear models, we might want to average the
    $\beta$ parameters \par}
  \pause
  \vspace{0.3cm}
%  {\bf But not all parameters are in every model. What do we do? \par}
  {But not all parameters are in every model. What do we do? \par}
  \pause
  \vspace{0.3cm}
%  {\bf Two options:}
  {Two options:}
  \begin{enumerate}[<+- | visible@+->][\bf \color{PineGreen} (1)]
    \item Average estimates over models {\it in which the parameter
        occurs} (bad idea)
    \item Average estimates over all models, and set the estimate to 0
      when the parameter is not in the model
  \end{enumerate}
\end{frame}


\begin{frame}
  \frametitle{Example}
  \begin{center}
    \begin{tabular}{lccccc}
      \hline
      Model & Intercept & Elevation & Elevation$^2$ & Chaparral & Weight \\
      \hline
      {\tt fm7} & 30.7 & 0.0083 & ---         & ---      & 0.80 \\
      {\tt fm8} & 28.0 & 0.012  & -0.0000026  & 0.093 & 0.19 \\
      \hline
      Average   & 29.9 & 0.0089 &  ???        & ???     &   \\
      \hline
    \end{tabular}
  \end{center}
\end{frame}




\begin{frame}
  \frametitle{Example}
  \begin{center}
    \begin{tabular}{lccccc}
      \hline
      Model & Intercept & Elevation & Elevation$^2$ & Chaparral & Weight \\
      \hline
      {\tt fm7} & 30.7 & 0.0083 & \alert{0}    & \alert{0}      & 0.80 \\
      {\tt fm8} & 28.0 & 0.012  & -0.0000026   & 0.093 & 0.19 \\
      \hline
      Average   & 29.9 & 0.0089 &  -0.0000005  & 0.018     &   \\
      \hline
    \end{tabular}
  \end{center}
  \pause
  \vfill
  Be aware that some people recommend that you never model average
  regression coefficients. However, it's always fine to model average
  predictions.
\end{frame}



\begin{frame}
  \frametitle{Model-averaged Predictions}
%  {\bf Same concept, applied to predicted values instead of parameter
%    estimates \par}
  {Same concept, applied to predicted values instead of parameter
    estimates \par}
  \pause
  \vspace{0.3cm}
%  {\bf Example: predict jay abundance when in Oak habitat at 1000 m
%    elevation, low seeds, and 10\% chaparral \par}
  {Example: predict jay abundance when in Oak habitat at 1000 m
    elevation, low seeds, and 10\% chaparral \par}
  \pause
  \begin{center}
    \begin{tabular}{lcc}
      \hline
      Model     & Predicted value ($\mathbb{E}(y)$) & Weight \\
      \hline
      {\tt fm7} & 42.17 & 0.80 \\
      {\tt fm8} & 45.95 & 0.19 \\
      \hline
      Average   & 42.47 & \\
      \hline
    \end{tabular}
  \end{center}
\end{frame}



\begin{frame}
  \frametitle{Model-averaged SEs and CIs}
  \large
%  {\bf We now know how to use model averaging to compute $\bar{\hat{\theta}}$}
  {We now know how to use model averaging to compute $\bar{\hat{\theta}}$}
  \pause
  \vfill
%  {\bf But, how do we calculate the SE or CI?}
  {But, how do we calculate the SE or CI?}
\end{frame}



\begin{frame}
  \frametitle{Unconditional SE}
  \Large
  \[
    \mbox{SE}(\bar{\hat{\theta}}) = \sum_{i=1}^R w_i \sqrt{\mbox{var}(\hat{\theta}_i) +
      (\hat{\theta}_i - \bar{\hat{\theta}})^2}
  \]
%  \pause
\end{frame}


\begin{frame}
  \frametitle{Example}
  \Large
  \begin{center}
    \begin{tabular}{lrrr}
      \hline
      Model & $\hat{\beta_1}$ & SE & $w$ \\
      \hline
      1 & 1.2 & 0.30 & 0.5 \\
      2 & 1.1 & 0.25 & 0.3 \\
      3 & 1.4 & 0.26 & 0.2 \\
      \hline
    \end{tabular}
  \end{center}
  \pause
  \large
  $\bar{\hat{\beta_1}} = 1.2\times0.5 + 1.1\times0.3 + 1.4\times0.2 = 1.21$
  \pause
  \begin{align*}
    \mbox{SE} = &0.5\sqrt{0.30^2 + (1.2-1.21)^2} + \\
                &0.3\sqrt{0.25^2 + (1.1-1.21)^2} + \\
                &0.2\sqrt{0.26^2 + (1.2-1.21)^2}   \\
              = &0.29
  \end{align*}
\end{frame}



%% \begin{frame}
%%   \frametitle{Unconditional CI}
%% %  {\bf 95\% CI}
%%   \Large
%%   \[
%%     \mbox{CI}(\bar{\hat{\theta}}) = \bar{\hat{\theta}} \pm z_{1-\alpha/2} \times \mbox{ASE}(\bar{\hat{\theta}})
%%   \] \par
%%   \pause
%%   \vspace{.5cm}
%%   where $\mbox{ASE}(\bar{\hat{\theta}})$ is the adjusted standard error:
%%   \vspace{.5cm}
%%   \[
%%     \mbox{ASE}(\bar{\hat{\theta}}) = \sum_{i=1}^R w_i
%%     \sqrt{\frac{t_{df_i, 1-\alpha/2}}{z_{1-\alpha/2}}\mbox{var}(\hat{\theta}_i) +
%%       (\hat{\theta}_i - \bar{\hat{\theta}})^2}
%%   \]
%% \end{frame}



\begin{frame}
  \frametitle{Relative variable importance}
%  {\bf Which of the predictor variables is most important? \par}
  {Which of the predictor variables is most important? \par}
  \vspace{0.5cm}
  \pause
%  {\bf Burnham and Anderson recommend using $w_+(\beta_j)$, the sum of
%    the AIC weights over all models that include $\beta_j$}
  {Burnham and Anderson recommend using $w_+(\beta_j)$, the sum of
    the AIC weights over all models that include $\beta_j$}
\end{frame}



\begin{frame}
  \frametitle{Example}
  \begin{center}
    \begin{tabular}{lrrrr}
      \hline
      Model & $\hat{\beta_1}$ & $\hat{\beta_2}$ & $\hat{\beta_3}$ & $w$ \\
      \hline
      1 & 1.2 & 2.0 & --  & 0.4 \\
      2 & 1.1 & --  & 0.6 & 0.3 \\
      3 & 1.4 & --  & 0.8 & 0.3 \\
      \hline
    \end{tabular}
  \end{center}
  \pause
  Variable importance values:
  \begin{align*}
    w_+(\hat{\beta_1}) &= 0.4 + 0.3 + 0.3 &= 1.0 \\
    w_+(\hat{\beta_2}) &= 0.4             &= 0.4 \\
    w_+(\hat{\beta_3}) &= 0.3 + 0.3       &= 0.6
  \end{align*}
\end{frame}














%% \section{In {\bf R}}








%% \begin{frame}[fragile]
%%   \frametitle{Prediction}
%%   \footnotesize
%%   {\bf Predict number of species at site 1000m high with 25\% forest
%%     cover, and no water, for \alert{each} model}
%% <<>>=
%% nd <- data.frame(elevation=1000, forest=25, water="No")
%% @
%% \pause
%% \vfill
%% <<>>=
%% E1 <- predict(fm1, newdata=nd, type="response")
%% as.numeric(E1) # as.numeric() removes names (optional)
%% @
%% \pause
%% \vfill
%% <<>>=
%% E2 <- predict(fm2, newdata=nd, type="response")
%% as.numeric(E2)
%% @
%% \pause
%% \vfill
%% <<>>=
%% E3 <- predict(fm3, newdata=nd, type="response")
%% as.numeric(E3)
%% @
%% \pause
%% \vfill
%% <<>>=
%% E4 <- predict(fm4, newdata=nd, type="response")
%% as.numeric(E4)
%% @
%% \end{frame}




%% \begin{frame}[fragile]
%%   \frametitle{Model-averaged prediction}
%%   {\bf Expected number of species at 1000m, 25\% forest cover, and no
%%     water, averaged over \alert{all} 4 models}
%%   \pause
%% <<>>=
%% sum(E1*w[1] + E2*w[2] + E3*w[3] + E4*w[4])
%% @
%% \end{frame}





%% \begin{frame}[fragile]
%%   \frametitle{Model-averaged regression lines}
%%   {\bf Predict species richness over range of forest cover, for each model}
%% <<>>=
%% nd <- data.frame(forest=seq(0, 100, length=50),
%%                  elevation=1000, water="No")
%% E1 <- predict(fm1, newdata=nd)
%% E2 <- predict(fm2, newdata=nd)
%% E3 <- predict(fm3, newdata=nd)
%% E4 <- predict(fm4, newdata=nd)
%% Emat <- cbind(E1, E2, E3, E4)
%% @
%% \pause
%% {\bf How do we model-average these vectors?}
%% \pause
%% <<>>=
%% Evec <- Emat %*% w
%% @
%% \end{frame}




%% \begin{frame}[fragile]
%%   \frametitle{Model-averaged regression lines}
%%   \tiny
%% <<reglines,fig=true,include=false>>=
%% plot(sppRichness ~ forest, data=swissData)
%% lines(E1 ~ forest, nd, col="grey")
%% lines(E2 ~ forest, nd, col="grey")
%% lines(E3 ~ forest, nd, col="grey")
%% lines(E4 ~ forest, nd, col="grey")
%% lines(Evec ~ forest, nd, col="blue", lwd=3)
%% @
%% \begin{center}
%%   \includegraphics[width=0.6\textwidth]{model-selection-reglines}
%% \end{center}
%% \end{frame}






















\begin{frame}
  \frametitle{Summary}
%  \large
%  \begin{itemize}%[<+->]
%    \item Information-theoretic approaches avoid many of the problems
%      associated with null hypothesis testing
    Information-theoretic approaches avoid many of the problems
      associated with null hypothesis testing
    \pause
    \vfill
%    \item Focus is on:
    Focus is on:
      \begin{itemize}
        \large
        \item Model comparision
        \item Strength of evidence for each model
        \item Estimates of effect sizes
      \end{itemize}
    \pause
    \vfill
%    \item Requires much more thought than accept/reject approach
    Requires much more thought than accept/reject approach, but just
    like any method, it is easy to abuse. 
%  \end{itemize}
  \pause
  \vfill
  Additional references
  \begin{itemize}
    \item[] {\bf Well known book:} Burnham, K.P. and
      D.R. Anderson. 2002. Model Selection and 
      Multimodel Inference. Springer.
    \item[] {\bf Great overview:} \url{http://www.stats.ox.ac.uk/~ripley/ModelChoice.pdf} 
  \end{itemize}
\end{frame}


\end{document}
